{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table_of_contents'></a>\n",
    "\n",
    "0. [Import libraries](#imports)\n",
    "1. [Import data](#import_data)\n",
    "2. [Initial Cleaning](#initial_cleaning)\n",
    "3. [Price and Quantity Cleaning](#price_and_quantity_cleaning)\n",
    "4. [Data Checks](#data_checks)\n",
    "5. [Export cleaned data](#export_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import libraries <a id='imports'></a>\n",
    "[Back to top](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipywidgets import VBox, HBox\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "mpl.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import raw data <a id='import_data'></a>\n",
    "[Back to top](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7890 entries, 0 to 7889\n",
      "Data columns (total 21 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   rating                             7890 non-null   object \n",
      " 1   roaster                            7890 non-null   object \n",
      " 2   title                              7890 non-null   object \n",
      " 3   blind_assessment                   7889 non-null   object \n",
      " 4   notes                              7888 non-null   object \n",
      " 5   bottom_line                        3812 non-null   object \n",
      " 6   roaster location                   7887 non-null   object \n",
      " 7   coffee origin                      7386 non-null   object \n",
      " 8   roast level                        7488 non-null   object \n",
      " 9   agtron                             7890 non-null   object \n",
      " 10  est. price                         5852 non-null   object \n",
      " 11  review date                        7890 non-null   object \n",
      " 12  aroma                              7830 non-null   object \n",
      " 13  acidity                            3730 non-null   object \n",
      " 14  body                               7879 non-null   object \n",
      " 15  flavor                             7874 non-null   object \n",
      " 16  aftertaste                         7019 non-null   float64\n",
      " 17  url                                7890 non-null   object \n",
      " 18  acidity/structure                  2903 non-null   float64\n",
      " 19  with milk                          1118 non-null   object \n",
      " 20  refresh(enable javascript first.)  4 non-null      object \n",
      "dtypes: float64(2), object(19)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read in raw data\n",
    "BASE_DIR = Path().resolve().parent\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "\n",
    "df_in = pd.read_csv(DATA_DIR / \"raw\" / \"25072024_reviews.csv\")\n",
    "df_in.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initial Cleaning <a id='initial_cleaning'></a>\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "First step is to do some of the basic data checks and cleanup. This includes dropping columns that are not needed, setting datatypes, renaming columns,\n",
    "combining columns, cleaning up strings, and creating new columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7890 entries, 0 to 7889\n",
      "Data columns (total 21 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   rating                            7890 non-null   object \n",
      " 1   roaster                           7890 non-null   object \n",
      " 2   title                             7890 non-null   object \n",
      " 3   blind_assessment                  7889 non-null   object \n",
      " 4   notes                             7888 non-null   object \n",
      " 5   bottom_line                       3812 non-null   object \n",
      " 6   roaster_location                  7887 non-null   object \n",
      " 7   coffee_origin                     7386 non-null   object \n",
      " 8   roast_level                       7488 non-null   object \n",
      " 9   agtron                            7890 non-null   object \n",
      " 10  est_price                         5852 non-null   object \n",
      " 11  review_date                       7890 non-null   object \n",
      " 12  aroma                             7830 non-null   object \n",
      " 13  acidity                           3730 non-null   object \n",
      " 14  body                              7879 non-null   object \n",
      " 15  flavor                            7874 non-null   object \n",
      " 16  aftertaste                        7019 non-null   float64\n",
      " 17  url                               7890 non-null   object \n",
      " 18  acidity/structure                 2903 non-null   float64\n",
      " 19  with_milk                         1118 non-null   object \n",
      " 20  refresh(enable_javascript_first)  4 non-null      object \n",
      "dtypes: float64(2), object(19)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Cleanup column names\n",
    "df_in.columns = (\n",
    "    df_in.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\".\", \"\")\n",
    ")\n",
    "\n",
    "df_in.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7566 entries, 0 to 7889\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   rating            7563 non-null   float64       \n",
      " 1   roaster           7566 non-null   object        \n",
      " 2   title             7566 non-null   object        \n",
      " 3   blind_assessment  7566 non-null   object        \n",
      " 4   notes             7565 non-null   object        \n",
      " 5   bottom_line       3758 non-null   object        \n",
      " 6   roaster_location  7564 non-null   object        \n",
      " 7   coffee_origin     7299 non-null   object        \n",
      " 8   roast_level       7445 non-null   object        \n",
      " 9   est_price         5790 non-null   object        \n",
      " 10  review_date       7566 non-null   datetime64[ns]\n",
      " 11  aroma             7540 non-null   float64       \n",
      " 12  acidity           6322 non-null   float64       \n",
      " 13  body              7556 non-null   float64       \n",
      " 14  flavor            7553 non-null   float64       \n",
      " 15  aftertaste        6954 non-null   float64       \n",
      " 16  url               7566 non-null   object        \n",
      " 17  with_milk         1082 non-null   object        \n",
      " 18  agtron_external   7566 non-null   float64       \n",
      " 19  agtron_ground     7566 non-null   float64       \n",
      " 20  is_espresso       7566 non-null   bool          \n",
      "dtypes: bool(1), datetime64[ns](1), float64(8), object(11)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "def tweak_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Initial data cleaning and feature creation\"\"\"\n",
    "    return (\n",
    "        df.assign(\n",
    "            review_date=lambda df_: pd.to_datetime(df_[\"review_date\"], format=\"%B %Y\"),\n",
    "            # Combing acidity and acidity/structure into one column, they are the same\n",
    "            # field but names used in reviews changed at one point\n",
    "            acidity=lambda df_: df_[\"acidity\"].fillna(df_[\"acidity/structure\"]),\n",
    "            # Split the agtron column into one for external bean agtron data and ground\n",
    "            # bean agtron data\n",
    "            agtron_external=lambda df_: pd.to_numeric(\n",
    "                df_[\"agtron\"].str.split(\"/\", expand=True)[0].str.strip(),\n",
    "                errors=\"coerce\",\n",
    "            ),\n",
    "            agtron_ground=lambda df_: pd.to_numeric(\n",
    "                df_[\"agtron\"].str.split(\"/\", expand=True)[1].str.strip(),\n",
    "                errors=\"coerce\",\n",
    "            ),\n",
    "            # Distinguish espresso roasts from other reviews\n",
    "            is_espresso=lambda df_: df_.apply(\n",
    "                lambda row: (\n",
    "                    True\n",
    "                    if \"espresso\" in row[\"title\"].lower()\n",
    "                    or pd.notnull(row[\"with_milk\"])\n",
    "                    else False\n",
    "                ),\n",
    "                axis=1,\n",
    "            ),\n",
    "        )\n",
    "        .replace([\"\", \"NR\", \"N/A\", \"na\"], np.nan)\n",
    "        # Agtron values must be equalt to or below 100, some entries on website have typos\n",
    "        .loc[\n",
    "            lambda df_: (df_[\"agtron_external\"] <= 100) & (df_[\"agtron_ground\"] <= 100),\n",
    "            :,\n",
    "        ]\n",
    "        # Run str.strip on every string column\n",
    "        .map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "        .drop(\n",
    "            columns=[\"acidity/structure\", \"agtron\", \"refresh(enable_javascript_first)\"]\n",
    "        )\n",
    "        .astype(\n",
    "            {\n",
    "                k: \"float\"\n",
    "                for k in [\n",
    "                    \"agtron_external\",\n",
    "                    \"agtron_ground\",\n",
    "                    \"acidity\",\n",
    "                    \"rating\",\n",
    "                    \"aroma\",\n",
    "                    \"body\",\n",
    "                    \"flavor\",\n",
    "                    \"aftertaste\",\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "df = tweak_df(df_in)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Price and Quantity Cleaning <a id='price_and_quantity_cleaning'></a>\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "The `est_price` column contains information on price, currency, and quantity. We need to split this column up to separate the price and quantity information.\n",
    "\n",
    "Splitting on \"/\" character creates one column with price and currency information and another with quantity and unit of measurement information. \n",
    "\n",
    "The quantities have to be standardized so they contain a single representation for each unit and so unecessary punctuation and parentheses are removed.\n",
    "\n",
    "We also filter the dataset to remove all products that came in units of cans, boxes, capusles, pods, etc. We will only concern ourselves with coffee sold in bags or bulk, ground or whole.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df shape: (7566, 21)\n",
      "Shape of price_quantity: (5607, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "quantity_unit\n",
       "ounces       4757\n",
       "grams         824\n",
       "pounds         17\n",
       "kilograms       9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_terms = [\n",
    "    \"can\",\n",
    "    \"box\",\n",
    "    \"capsules\",\n",
    "    \"K-\",\n",
    "    \"cups\",\n",
    "    \"bags\",\n",
    "    \"concentrate\",\n",
    "    \"discs\",\n",
    "    \"bottle\",\n",
    "    \"pods\",\n",
    "    \"ml\",\n",
    "    \"pods\",\n",
    "    \"pouch\",\n",
    "    \"packet|tin\",\n",
    "    \"instant\",\n",
    "    \"sachet\",\n",
    "    \"vue\",\n",
    "    \"single-serve\",\n",
    "    \"fluid\",\n",
    "    \"capsultes\",\n",
    "]\n",
    "\n",
    "drop_terms_string = \"|\".join(drop_terms)\n",
    "\n",
    "\n",
    "def price_quantity_split(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(f\"Original df shape: {df.shape}\")\n",
    "    price_quantity = (\n",
    "        df\n",
    "        # Split est_price into columns for price and quantity\n",
    "        .est_price.str.split(\"/\", n=1, expand=True)\n",
    "        # Remove any commas from the price and quantity columns\n",
    "        .replace(\",\", \"\", regex=True)\n",
    "        .rename(columns={0: \"price\", 1: \"quantity\"})\n",
    "        .assign(\n",
    "            # Cleanup quantity\n",
    "            quantity=lambda df_: (\n",
    "                df_[\"quantity\"]\n",
    "                .str.lower().str.strip()\n",
    "                # Remove parentheses and anything inside them\n",
    "                .str.replace(r\"\\(.*?\\)\", \"\", regex=True)\n",
    "                # Remove anything after a semicolon. This is usually a note, or deal price.\n",
    "                .str.replace(r\";.*\", \"\", regex=True)\n",
    "                # Standardize units\n",
    "                .str.replace(r\".g$\", \" grams\", regex=True)\n",
    "                .str.replace(r\"\\sg$\", \"grams\", regex=True)\n",
    "                .str.replace(r\"\\bgram$\", \"grams\", regex=True)\n",
    "                .str.replace(r\"pound$\", \"1 pounds\", regex=True)\n",
    "                .str.replace(r\"oz|onces|ouncues|ounce$|ounces\\*\", \"ounces\", regex=True)\n",
    "                .str.replace(\"kilogram\", \"kilograms\")\n",
    "                .str.replace(\"kg\", \"kilograms\")\n",
    "                # Remove \"online\" from any quantity\n",
    "                .str.replace(\"online\", \"\")\n",
    "                .str.strip()\n",
    "            ),\n",
    "            price=lambda df_: df_[\"price\"].str.replace(\"..\", \".\"),\n",
    "        )\n",
    "        .dropna()\n",
    "        # Remove rows where coffee is sold in a can, box, pouch, packet, or tin\n",
    "        .loc[\n",
    "            lambda df_: ~df_[\"quantity\"].str.contains(drop_terms_string, case=False),\n",
    "            :,\n",
    "        ]\n",
    "        # Split quantity into value and unit, and split price into value and currency\n",
    "        .assign(\n",
    "            # Extract number value from quantity\n",
    "            quantity_value=lambda df_: (\n",
    "                df_[\"quantity\"].str.extract(r\"(\\d+)\").astype(float)\n",
    "            ),\n",
    "            # Extract the unit from quantity column\n",
    "            quantity_unit=lambda df_: (\n",
    "                df_[\"quantity\"]\n",
    "                .str.replace(r\"(\\d+)\", \"\", regex=True)\n",
    "                .replace(\"\\.\", \"\", regex=True)\n",
    "                .str.strip()\n",
    "                .mask(lambda s: s == \"g\", \"grams\")\n",
    "                .mask(lambda s: s == \"kilo\", \"kilograms\")\n",
    "                .str.strip()\n",
    "            ),\n",
    "            # Extract price value from price column\n",
    "            price_value=lambda df_: (\n",
    "                df_[\"price\"].str.extract(r\"(\\d+\\.\\d+|\\d+)\").astype(float)\n",
    "            ),\n",
    "            # Extract currency from price column\n",
    "            price_currency=lambda df_: (\n",
    "                df_[\"price\"]\n",
    "                .str.replace(\",\", \"\")\n",
    "                .str.replace(r\"(\\d+\\.\\d+|\\d+)\", \"\", regex=True)\n",
    "                .str.strip()\n",
    "            ),\n",
    "        )\n",
    "        # Drop the original price and quantity columns\n",
    "        .drop(columns=[\"price\", \"quantity\"])\n",
    "        # remove rows where quantity_unit contains (\n",
    "        .loc[lambda df_: ~df_[\"quantity_unit\"].str.contains(r\"\\(\", regex=True), :]\n",
    "        )\n",
    "    print(f\"Shape of price_quantity: {price_quantity.shape}\")\n",
    "\n",
    "    # Merge the price_quantity DataFrame with the original DataFrame\n",
    "    return df.merge(price_quantity, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "df = df_in.pipe(tweak_df).pipe(price_quantity_split)\n",
    "\n",
    "df.quantity_unit.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Prices and Currencies\n",
    "Normalize the currency column to contain a standardized set of currency symbols. We will use the ISO 4217 codes to make it easier to get foreign exchange data from an external API later on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df shape: (7566, 21)\n",
      "Shape of price_quantity: (5607, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>est_price</th>\n",
       "      <th>price_currency</th>\n",
       "      <th>price_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>AED $99.75/250 grams</td>\n",
       "      <td>AED</td>\n",
       "      <td>99.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>AED $103.95/250 grams</td>\n",
       "      <td>AED</td>\n",
       "      <td>103.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7560</th>\n",
       "      <td>AED $99.75/250 grams</td>\n",
       "      <td>AED</td>\n",
       "      <td>99.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>AUD $22.00/250 grams</td>\n",
       "      <td>AUD</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>AUD $48.00/200 grams</td>\n",
       "      <td>AUD</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>AUD $16.00/250 grams</td>\n",
       "      <td>AUD</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6798</th>\n",
       "      <td>CAD $52.50/12 ounces</td>\n",
       "      <td>CAD</td>\n",
       "      <td>52.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>CAD $21.00/12 ounces</td>\n",
       "      <td>CAD</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>CAD $14.00/16 ounces</td>\n",
       "      <td>CAD</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4327</th>\n",
       "      <td>RMB $75.00/150 grams</td>\n",
       "      <td>CNY</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>CNY $90/227 grams</td>\n",
       "      <td>CNY</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>RMB $60/125 grams</td>\n",
       "      <td>CNY</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>€29.95/1 kilo (35.3 ounces)</td>\n",
       "      <td>EUR</td>\n",
       "      <td>29.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6557</th>\n",
       "      <td>E 50.00/250 grams</td>\n",
       "      <td>EUR</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>E 11.90/220 grams</td>\n",
       "      <td>EUR</td>\n",
       "      <td>11.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>£7.45/250 grams</td>\n",
       "      <td>GBP</td>\n",
       "      <td>7.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>#23.00/12 ounces</td>\n",
       "      <td>GBP</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>£7.00/250 grams</td>\n",
       "      <td>GBP</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>GTQ 100/12 ounces</td>\n",
       "      <td>GTQ</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>GTQ 100/12 ounces</td>\n",
       "      <td>GTQ</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>GTQ 100/12 ounces</td>\n",
       "      <td>GTQ</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166</th>\n",
       "      <td>HK $98/165 grams</td>\n",
       "      <td>HKD</td>\n",
       "      <td>98.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>HK $98/165 grams</td>\n",
       "      <td>HKD</td>\n",
       "      <td>98.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>HK $588/100 grams</td>\n",
       "      <td>HKD</td>\n",
       "      <td>588.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>IDR $120,000/200 grams</td>\n",
       "      <td>IDR</td>\n",
       "      <td>120000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>IDR $120,000/200 grams</td>\n",
       "      <td>IDR</td>\n",
       "      <td>120000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>IDR $120,000/200 grams</td>\n",
       "      <td>IDR</td>\n",
       "      <td>120000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>¥ 2,420/200 grams</td>\n",
       "      <td>JPY</td>\n",
       "      <td>2420.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6282</th>\n",
       "      <td>¥ 2,640/50 grams</td>\n",
       "      <td>JPY</td>\n",
       "      <td>2640.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>¥1280/100 grams</td>\n",
       "      <td>JPY</td>\n",
       "      <td>1280.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>KRW 19,000/200 grams</td>\n",
       "      <td>KRW</td>\n",
       "      <td>19000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4326</th>\n",
       "      <td>KRW 95,000/100 grams</td>\n",
       "      <td>KRW</td>\n",
       "      <td>95000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>KRW 40,000/500 grams</td>\n",
       "      <td>KRW</td>\n",
       "      <td>40000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>$35,000 LAK/250 grams</td>\n",
       "      <td>LAK</td>\n",
       "      <td>35000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>$35,000 LAK/250 grams</td>\n",
       "      <td>LAK</td>\n",
       "      <td>35000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>$35,000 LAK/250 grams</td>\n",
       "      <td>LAK</td>\n",
       "      <td>35000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>500 pesos/200 grams</td>\n",
       "      <td>MXN</td>\n",
       "      <td>500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>500 pesos/200 grams</td>\n",
       "      <td>MXN</td>\n",
       "      <td>500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>500 pesos/200 grams</td>\n",
       "      <td>MXN</td>\n",
       "      <td>500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>RM 120/350 grams</td>\n",
       "      <td>RM</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>RM 120/350 grams</td>\n",
       "      <td>RM</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>RM 120/350 grams</td>\n",
       "      <td>RM</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>THB 150/250 g.</td>\n",
       "      <td>THB</td>\n",
       "      <td>150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>THB $200/250 grams</td>\n",
       "      <td>THB</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7451</th>\n",
       "      <td>THB $250/250 grams</td>\n",
       "      <td>THB</td>\n",
       "      <td>250.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>NTD $2600/8 ounces</td>\n",
       "      <td>TWD</td>\n",
       "      <td>2600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>NT $310/8 ounces</td>\n",
       "      <td>TWD</td>\n",
       "      <td>310.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>NT $800/227 grams</td>\n",
       "      <td>TWD</td>\n",
       "      <td>800.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>$19.20/12 ounces</td>\n",
       "      <td>USD</td>\n",
       "      <td>19.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>$13.00/12 ounces</td>\n",
       "      <td>USD</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6667</th>\n",
       "      <td>$18.00/500 g (17.6 oz.)</td>\n",
       "      <td>USD</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        est_price price_currency  price_value\n",
       "5999         AED $99.75/250 grams            AED        99.75\n",
       "1462        AED $103.95/250 grams            AED       103.95\n",
       "7560         AED $99.75/250 grams            AED        99.75\n",
       "320          AUD $22.00/250 grams            AUD        22.00\n",
       "7640         AUD $48.00/200 grams            AUD        48.00\n",
       "1030         AUD $16.00/250 grams            AUD        16.00\n",
       "6798         CAD $52.50/12 ounces            CAD        52.50\n",
       "1383         CAD $21.00/12 ounces            CAD        21.00\n",
       "3994         CAD $14.00/16 ounces            CAD        14.00\n",
       "4327         RMB $75.00/150 grams            CNY        75.00\n",
       "5459            CNY $90/227 grams            CNY        90.00\n",
       "5966            RMB $60/125 grams            CNY        60.00\n",
       "3079  €29.95/1 kilo (35.3 ounces)            EUR        29.95\n",
       "6557            E 50.00/250 grams            EUR        50.00\n",
       "4617            E 11.90/220 grams            EUR        11.90\n",
       "5552              £7.45/250 grams            GBP         7.45\n",
       "2768             #23.00/12 ounces            GBP        23.00\n",
       "2890              £7.00/250 grams            GBP         7.00\n",
       "1575            GTQ 100/12 ounces            GTQ       100.00\n",
       "1575            GTQ 100/12 ounces            GTQ       100.00\n",
       "1575            GTQ 100/12 ounces            GTQ       100.00\n",
       "6166             HK $98/165 grams            HKD        98.00\n",
       "1617             HK $98/165 grams            HKD        98.00\n",
       "4514            HK $588/100 grams            HKD       588.00\n",
       "5002       IDR $120,000/200 grams            IDR    120000.00\n",
       "1717       IDR $120,000/200 grams            IDR    120000.00\n",
       "1717       IDR $120,000/200 grams            IDR    120000.00\n",
       "4225            ¥ 2,420/200 grams            JPY      2420.00\n",
       "6282             ¥ 2,640/50 grams            JPY      2640.00\n",
       "487               ¥1280/100 grams            JPY      1280.00\n",
       "4553         KRW 19,000/200 grams            KRW     19000.00\n",
       "4326         KRW 95,000/100 grams            KRW     95000.00\n",
       "4814         KRW 40,000/500 grams            KRW     40000.00\n",
       "6149        $35,000 LAK/250 grams            LAK     35000.00\n",
       "6149        $35,000 LAK/250 grams            LAK     35000.00\n",
       "6149        $35,000 LAK/250 grams            LAK     35000.00\n",
       "4945          500 pesos/200 grams            MXN       500.00\n",
       "4945          500 pesos/200 grams            MXN       500.00\n",
       "4945          500 pesos/200 grams            MXN       500.00\n",
       "1808             RM 120/350 grams             RM       120.00\n",
       "5923             RM 120/350 grams             RM       120.00\n",
       "1808             RM 120/350 grams             RM       120.00\n",
       "3800               THB 150/250 g.            THB       150.00\n",
       "4292           THB $200/250 grams            THB       200.00\n",
       "7451           THB $250/250 grams            THB       250.00\n",
       "5269           NTD $2600/8 ounces            TWD      2600.00\n",
       "5870             NT $310/8 ounces            TWD       310.00\n",
       "1727            NT $800/227 grams            TWD       800.00\n",
       "4385             $19.20/12 ounces            USD        19.20\n",
       "225              $13.00/12 ounces            USD        13.00\n",
       "6667      $18.00/500 g (17.6 oz.)            USD        18.00"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_currency(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Standardize currencies to ISO 4217 codes.\"\"\"\n",
    "    price_currency = (\n",
    "        df.price_currency.str.upper()\n",
    "        .str.replace(r\"^\\$$\", \"USD\", regex=True)\n",
    "        .str.replace(\"PRICE: $\", \"USD\")\n",
    "        .str.replace(\"$\", \"\")\n",
    "        .str.replace(\"#\", \"GBP\")\n",
    "        .str.replace(\"¥\", \"JPY\")\n",
    "        .str.replace(\"£\", \"GBP\")\n",
    "        .str.replace(\"€\", \"EUR\")\n",
    "        .str.replace(\"POUND\", \"GBP\")\n",
    "        .str.replace(\"PESOS\", \"MXN\")\n",
    "        .str.replace(\"RMB\", \"CNY\")\n",
    "        .str.replace(\"EUROS\", \"EUR\")\n",
    "        .str.strip()\n",
    "        .mask(lambda s: s == \"US\", \"USD\")\n",
    "        .mask(lambda s: s == \" \", \"USD\")\n",
    "        .mask(lambda s: s == \"E\", \"EUR\")\n",
    "        .mask(lambda s: s == \"NTD\", \"TWD\")\n",
    "        .mask(lambda s: s == \"NT\", \"TWD\")\n",
    "        .mask(lambda s: s == \"\", \"USD\")\n",
    "        .mask(lambda s: s == \"HK\", \"HKD\")\n",
    "        .str.strip()\n",
    "    )\n",
    "    return df.assign(price_currency=price_currency)\n",
    "\n",
    "\n",
    "df = (df_in\n",
    "      .pipe(tweak_df)\n",
    "      .pipe(price_quantity_split)\n",
    "      .pipe(clean_currency)\n",
    ")\n",
    "\n",
    "\n",
    "# Check that currencies make sense from original est_price column\n",
    "df.loc[:, [\"est_price\", \"price_currency\", \"price_value\"]].groupby(\n",
    "    \"price_currency\"\n",
    ").sample(3, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_currency\n",
       "USD    4249\n",
       "TWD    1067\n",
       "CAD     125\n",
       "HKD      46\n",
       "CNY      27\n",
       "THB      21\n",
       "KRW      20\n",
       "JPY      12\n",
       "GBP      10\n",
       "AUD      10\n",
       "EUR       6\n",
       "AED       5\n",
       "RM        3\n",
       "IDR       3\n",
       "GTQ       1\n",
       "MXN       1\n",
       "LAK       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price_currency.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting prices to 2024 USD\n",
    "\n",
    "1. Convert price to USD using historical exchange rates\n",
    "2. Adjust price to 2024 USD using BLS consumer price index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df shape: (7566, 21)\n",
      "Shape of price_quantity: (5607, 4)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'2004-10-01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 24\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(DATA_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenex_exchange_rates.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     18\u001b[0m     exchange_rates \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     20\u001b[0m df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     21\u001b[0m     \u001b[43mdf_in\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweak_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice_quantity_split\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_currency\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_to_usd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m (\n\u001b[1;32m     28\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[:, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_currency\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_value_usd_hist\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mgroupby(\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_currency\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m )\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m3\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/coffee-review/venv/lib/python3.11/site-packages/pandas/core/generic.py:6231\u001b[0m, in \u001b[0;36mNDFrame.pipe\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m   6230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m common\u001b[38;5;241m.\u001b[39mpipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 6231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/coffee-review/venv/lib/python3.11/site-packages/pandas/core/common.py:502\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(obj, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[101], line 12\u001b[0m, in \u001b[0;36mconvert_to_usd\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_usd\u001b[39m(df: pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m---> 12\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_value_usd_hist\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/Projects/coffee-review/venv/lib/python3.11/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/coffee-review/venv/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/coffee-review/venv/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/Projects/coffee-review/venv/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[101], line 8\u001b[0m, in \u001b[0;36mconvert_row\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m price\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mround(price \u001b[38;5;241m/\u001b[39m \u001b[43mexchange_rates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m]\u001b[49m[currency], \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '2004-10-01'"
     ]
    }
   ],
   "source": [
    "def convert_row(row):\n",
    "    date = row[\"review_date\"].strftime(\"%Y-%m-%d\")\n",
    "    currency = row[\"price_currency\"]\n",
    "    price = row[\"price_value\"]\n",
    "    if currency == \"USD\":\n",
    "        return price\n",
    "    else:\n",
    "        return np.round(price / exchange_rates[date][currency], 2)\n",
    "\n",
    "\n",
    "def convert_to_usd(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"price_value_usd_hist\"] = df.apply(convert_row, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Read in exchange rates\n",
    "with open(DATA_DIR / \"external\" / \"openex_exchange_rates.json\") as f:\n",
    "    exchange_rates = json.load(f)\n",
    "\n",
    "df = (\n",
    "    df_in.pipe(tweak_df)\n",
    "    .pipe(price_quantity_split)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_to_usd)\n",
    ")\n",
    "\n",
    "(\n",
    "    df.loc[:, [\"price_value\", \"price_currency\", \"price_value_usd_hist\"]].groupby(\n",
    "        \"price_currency\"\n",
    "    )\n",
    ").sample(3, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transform_cpi(file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Loads and transforms the CPI data.\"\"\"\n",
    "    MONTH_MAP = {\n",
    "        \"Jan\": 1,\n",
    "        \"Feb\": 2,\n",
    "        \"Mar\": 3,\n",
    "        \"Apr\": 4,\n",
    "        \"May\": 5,\n",
    "        \"Jun\": 6,\n",
    "        \"Jul\": 7,\n",
    "        \"Aug\": 8,\n",
    "        \"Sep\": 9,\n",
    "        \"Oct\": 10,\n",
    "        \"Nov\": 11,\n",
    "        \"Dec\": 12,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        cpi = pd.read_csv(\n",
    "            file_path,\n",
    "            usecols=[\n",
    "                \"Year\",\n",
    "                \"Jan\",\n",
    "                \"Feb\",\n",
    "                \"Mar\",\n",
    "                \"Apr\",\n",
    "                \"May\",\n",
    "                \"Jun\",\n",
    "                \"Jul\",\n",
    "                \"Aug\",\n",
    "                \"Sep\",\n",
    "                \"Oct\",\n",
    "                \"Nov\",\n",
    "                \"Dec\",\n",
    "            ],\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"CPI file is not found in the specified directory.\")\n",
    "\n",
    "    return (\n",
    "        cpi.melt(id_vars=\"Year\", var_name=\"Month\", value_name=\"cpi\")\n",
    "        .assign(\n",
    "            Month=lambda x: x[\"Month\"].map(MONTH_MAP),\n",
    "            date=lambda x: pd.to_datetime(x[[\"Year\", \"Month\"]].assign(day=1)),\n",
    "        )\n",
    "        .dropna()\n",
    "        .drop(columns=[\"Year\", \"Month\"])\n",
    "        .rename(columns={\"cpi\": \"consumer_price_index\"})\n",
    "        .sort_values(\"date\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def create_cpi_adjusted_price(\n",
    "    df: pd.DataFrame, file_path: Path, date: str = \"2024-01-01\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adjusts historical price data to 2024 prices using CPI data.\n",
    "    \"\"\"\n",
    "    cpi = load_transform_cpi(file_path)\n",
    "    cpi_baseline = cpi.loc[cpi[\"date\"] == date, \"consumer_price_index\"].values[0]\n",
    "\n",
    "    return (\n",
    "        df.merge(cpi, left_on=\"review_date\", right_on=\"date\")\n",
    "        .drop(columns=\"date\")\n",
    "        .assign(\n",
    "            price_usd_adj_2024=lambda df_: np.round(\n",
    "                df_[\"price_value_usd_hist\"]\n",
    "                * cpi_baseline\n",
    "                / df_[\"consumer_price_index\"],\n",
    "                2,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "data_dir = Path(\"../../data\")\n",
    "cpi_path = data_dir / \"external\" / \"consumer_price_index.csv\"\n",
    "\n",
    "df = (\n",
    "    df_in.pipe(tweak_df)\n",
    "    .pipe(price_quantity_split)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_to_usd)\n",
    "    .pipe(create_cpi_adjusted_price, file_path=cpi_path)\n",
    ")\n",
    "\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.assign(\n",
    "        price_diff=lambda df_: (df_[\"price_usd_adj_2024\"] - df_[\"price_value_usd_hist\"])\n",
    "        / df_[\"price_usd_adj_2024\"]\n",
    "    )\n",
    ").plot(\n",
    "    x=\"review_date\",\n",
    "    y=\"price_diff\",\n",
    "    title=\"% Price difference between adjusted and historical prices\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting quantities to lbs\n",
    "\n",
    "Create a normalized quantity column that converts all quantities to lbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lbs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    to_lbs_conversion = {\n",
    "        \"ounces\": 1 / 16,\n",
    "        \"pounds\": 1,\n",
    "        \"kilogram\": 2.20462,\n",
    "        \"grams\": 0.00220462,\n",
    "    }\n",
    "    df[\"quantity_in_lbs\"] = np.round(\n",
    "        df[\"quantity_value\"] * df[\"quantity_unit\"].map(to_lbs_conversion), 2\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df = (\n",
    "    df_raw.pipe(tweak_df)\n",
    "    .pipe(price_quantity_split)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_to_usd)\n",
    "    .pipe(create_cpi_adjusted_price, file_path=cpi_path)\n",
    "    .pipe(convert_to_lbs)\n",
    ")\n",
    "\n",
    "(\n",
    "    df.loc[:, [\"quantity_value\", \"quantity_unit\", \"quantity_in_lbs\"]]\n",
    "    .groupby(\"quantity_unit\")\n",
    "    .sample(3, replace=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for price per pound\n",
    "def price_per_lbs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"price_usd_adj_2024_per_lb\"] = np.round(\n",
    "        df[\"price_usd_adj_2024\"] / df[\"quantity_in_lbs\"], 2\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df = (\n",
    "    df_raw.pipe(tweak_df)\n",
    "    .pipe(price_quantity_split)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_to_usd)\n",
    "    .pipe(create_cpi_adjusted_price, file_path=cpi_path)\n",
    "    .pipe(convert_to_lbs)\n",
    "    .pipe(price_per_lbs)\n",
    ")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of US states\n",
    "us_states_and_territories = [\n",
    "    \"Alabama\",\n",
    "    \"Alaska\",\n",
    "    \"Arizona\",\n",
    "    \"Arkansas\",\n",
    "    \"California\",\n",
    "    \"Colorado\",\n",
    "    \"Connecticut\",\n",
    "    \"Delaware\",\n",
    "    \"Florida\",\n",
    "    \"Georgia\",\n",
    "    \"Hawaii\",\n",
    "    \"Idaho\",\n",
    "    \"Illinois\",\n",
    "    \"Indiana\",\n",
    "    \"Iowa\",\n",
    "    \"Kansas\",\n",
    "    \"Kentucky\",\n",
    "    \"Louisiana\",\n",
    "    \"Maine\",\n",
    "    \"Maryland\",\n",
    "    \"Massachusetts\",\n",
    "    \"Michigan\",\n",
    "    \"Minnesota\",\n",
    "    \"Mississippi\",\n",
    "    \"Missouri\",\n",
    "    \"Montana\",\n",
    "    \"Nebraska\",\n",
    "    \"Nevada\",\n",
    "    \"New Hampshire\",\n",
    "    \"New Jersey\",\n",
    "    \"New Mexico\",\n",
    "    \"New York\",\n",
    "    \"North Carolina\",\n",
    "    \"North Dakota\",\n",
    "    \"Ohio\",\n",
    "    \"Oklahoma\",\n",
    "    \"Oregon\",\n",
    "    \"Pennsylvania\",\n",
    "    \"Rhode Island\",\n",
    "    \"South Carolina\",\n",
    "    \"South Dakota\",\n",
    "    \"Tennessee\",\n",
    "    \"Texas\",\n",
    "    \"Utah\",\n",
    "    \"Vermont\",\n",
    "    \"Virginia\",\n",
    "    \"Washington\",\n",
    "    \"West Virginia\",\n",
    "    \"Wisconsin\",\n",
    "    \"Wyoming\",\n",
    "    \"District of Columbia\",\n",
    "    \"Puerto Rico\",\n",
    "]\n",
    "\n",
    "\n",
    "def create_us_state(row):\n",
    "    if row[\"territorial_entity_2\"] in us_states_and_territories:\n",
    "        return row[\"territorial_entity_2\"]\n",
    "    elif row[\"territorial_entity_1\"] in us_states_and_territories:\n",
    "        return row[\"territorial_entity_1\"]\n",
    "    elif row[\"og_roaster_location\"].split(\",\")[-1].strip() in us_states_and_territories:\n",
    "        return row[\"og_roaster_location\"].split(\",\")[-1].strip()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def create_county_and_state_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"roaster_county\"] = np.where(\n",
    "        df[\"territorial_entity_1\"].str.contains(\"County\", na=False),\n",
    "        df[\"territorial_entity_1\"],\n",
    "        np.nan,\n",
    "    )\n",
    "    df[\"roaster_us_state\"] = df.apply(create_us_state, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = (\n",
    "    df_raw.pipe(tweak_df)\n",
    "    .pipe(price_quantity_split)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_to_usd)\n",
    "    .pipe(create_cpi_adjusted_price, file_path=cpi_path)\n",
    "    .pipe(convert_to_lbs)\n",
    "    .pipe(price_per_lbs)\n",
    "    .pipe(create_county_and_state_columns)\n",
    ")\n",
    "\n",
    "display(\n",
    "    df.loc[\n",
    "        df[\"roaster_country\"] == \"USA\",\n",
    "        [\"roaster_country\", \"roaster_us_state\", \"roaster_county\"],\n",
    "    ].info()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Checks <a id='data_checks'></a>\n",
    "[Back to top](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df_raw.pipe(tweak_df)\n",
    "    .pipe(price_quantity_split)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_to_usd)\n",
    "    .pipe(create_cpi_adjusted_price, file_path=cpi_path)\n",
    "    .pipe(convert_to_lbs)\n",
    "    .pipe(price_per_lbs)\n",
    "    .pipe(create_county_and_state_columns)\n",
    ")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=[\"number\"]).drop(columns=[\"price_value\"], axis=1)\n",
    "len(df_numeric.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 5, figsize=(15, 10))\n",
    "\n",
    "for i, col in enumerate(df_numeric.columns):\n",
    "    df[col].plot(\n",
    "        kind=\"hist\",\n",
    "        ax=ax[i // 5, i % 5],\n",
    "        title=col,\n",
    "        bins=20,\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"price_usd_adj_2024_per_lb\"] < 200].price_usd_adj_2024_per_lb.hist(\n",
    "    cumulative=True, density=True, edgecolor=\"black\", alpha=0.7\n",
    ")\n",
    "plt.title(\"Cumulative Histogram Price $USD/lbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking countries\n",
    "display(df.roaster_country.sort_values().unique())\n",
    "display(df.coffee_origin_country.sort_values().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking roast level\n",
    "df.roast_level.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Export cleaned data <a id='export_data'></a>\n",
    "[Back to top](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = data_dir / \"processed\" / \"05052024_roast_review_cleaned.csv\"\n",
    "df.to_csv(fout, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffee-review-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
