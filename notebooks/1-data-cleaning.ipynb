{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table_of_contents'></a>\n",
    "\n",
    "0. [Import libraries](#imports)\n",
    "1. [Load data](#load_data)\n",
    "2. [Initial Cleaning](#initial_cleaning)\n",
    "3. [Price and Quantity Cleaning](#price_and_quantity_cleaning)\n",
    "4. [Coffee Origin Cleaning](#coffee_origin_cleaning)\n",
    "5. [Export processed data](#export_data)\n",
    "6. [External processing](#external_processing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import libraries <a id='imports'></a>\n",
    "[Back to top](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "from unidecode import unidecode\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "mpl.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = Path().resolve().parent\n",
    "if str(basedir) not in sys.path:\n",
    "    sys.path.insert(0, str(basedir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import raw data <a id='load_data'></a>\n",
    "[Back to top](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "BASE_DIR: Path = Path().resolve().parent\n",
    "DATA_DIR: Path = BASE_DIR / \"data\"\n",
    "FILE_IN: str = \"25072024_reviews.csv\"\n",
    "\n",
    "# Load data\n",
    "df_in: pd.DataFrame = pd.read_csv(DATA_DIR / \"raw\" / FILE_IN)\n",
    "df_in.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initial Cleaning <a id='initial_cleaning'></a>\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "First step is basic data checks and cleaning. This includes renaming and combining and creating columns, dropping unecessary columns, setting datatypes, and string cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup column names\n",
    "df_in.columns = (\n",
    "    df_in.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\".\", \"\")\n",
    ")\n",
    "\n",
    "df_in.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Initial data cleaning\"\"\"\n",
    "    return (\n",
    "        df.assign(\n",
    "            review_date=lambda df_: pd.to_datetime(df_[\"review_date\"], format=\"%B %Y\"),\n",
    "            # Combing acidity and acidity/structure into one column, they are the same\n",
    "            # field but names used in reviews changed at one point\n",
    "            acidity=lambda df_: df_[\"acidity\"].fillna(df_[\"acidity/structure\"]),\n",
    "            # Split the agtron column into one for external bean agtron data and ground\n",
    "            # bean agtron data\n",
    "            agtron_external=lambda df_: pd.to_numeric(\n",
    "                df_[\"agtron\"].str.split(\"/\", expand=True)[0].str.strip(),\n",
    "                errors=\"coerce\",\n",
    "            ),\n",
    "            agtron_ground=lambda df_: pd.to_numeric(\n",
    "                df_[\"agtron\"].str.split(\"/\", expand=True)[1].str.strip(),\n",
    "                errors=\"coerce\",\n",
    "            ),\n",
    "            # Distinguish espresso roasts from other reviews\n",
    "            is_espresso=lambda df_: df_.apply(\n",
    "                lambda row: (\n",
    "                    True\n",
    "                    if \"espresso\" in row[\"title\"].lower()\n",
    "                    or pd.notnull(row[\"with_milk\"])\n",
    "                    else False\n",
    "                ),\n",
    "                axis=1,\n",
    "            ),\n",
    "        )\n",
    "        .replace([\"\", \"NR\", \"N/A\", \"na\"], np.nan)\n",
    "        # Agtron values must be equalt to or below 100,\n",
    "        # some entries on website have typos\n",
    "        .loc[\n",
    "            lambda df_: (df_[\"agtron_external\"] <= 100) & (df_[\"agtron_ground\"] <= 100),\n",
    "            :,\n",
    "        ]\n",
    "        # Run str.strip on every string column\n",
    "        .map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "        .drop(\n",
    "            columns=[\"acidity/structure\", \"agtron\", \"refresh(enable_javascript_first)\"]\n",
    "        )\n",
    "        .astype(\n",
    "            {\n",
    "                k: \"float\"\n",
    "                for k in [\n",
    "                    \"agtron_external\",\n",
    "                    \"agtron_ground\",\n",
    "                    \"acidity\",\n",
    "                    \"rating\",\n",
    "                    \"aroma\",\n",
    "                    \"body\",\n",
    "                    \"flavor\",\n",
    "                    \"aftertaste\",\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "df: pd.DataFrame = tweak_df(df_in)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Price and Quantity Cleaning <a id='price_and_quantity_cleaning'></a>\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "The `est_price` column contains information on coffe roast price, quantity, and currency. We split this column to separate price and quantity information. Splitting on \"/\" creates one column with the price and currency and another with the quantity and unit of measure. Quantities need to be standardized to a single representation for each unit. We also filter out all products that came in units of cans, boxes, capusles, pods, etc. We will ignore extra-processed coffee and only concern ourselves with coffee sold in bags or bulk, whether ground or whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list of quantity terms to drop from the dataset\n",
    "drop_terms: list[str] = [\n",
    "    \"can\",\n",
    "    \"box\",\n",
    "    \"capsules\",\n",
    "    \"K-\",\n",
    "    \"cups\",\n",
    "    \"bags\",\n",
    "    \"concentrate\",\n",
    "    \"discs\",\n",
    "    \"bottle\",\n",
    "    \"pods\",\n",
    "    \"ml\",\n",
    "    \"pods\",\n",
    "    \"pouch\",\n",
    "    \"packet|tin\",\n",
    "    \"instant\",\n",
    "    \"sachet\",\n",
    "    \"vue\",\n",
    "    \"single-serve\",\n",
    "    \"fluid\",\n",
    "    \"capsultes\",\n",
    "]\n",
    "\n",
    "# Build a regex string to match any of the drop terms\n",
    "drop_terms_string: str = \"|\".join(drop_terms)\n",
    "\n",
    "\n",
    "def price_quantity_split(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Split the est_price column into price and quantity columns\"\"\"\n",
    "    price_quantity = (\n",
    "        df\n",
    "        # Split est_price into columns for price and quantity\n",
    "        .est_price.str.split(\"/\", n=1, expand=True)\n",
    "        # Remove any commas from the price and quantity columns\n",
    "        .replace(\",\", \"\", regex=True)\n",
    "        .rename(columns={0: \"price\", 1: \"quantity\"})\n",
    "        .assign(\n",
    "            # Cleanup quantity\n",
    "            quantity=lambda df_: (\n",
    "                df_[\"quantity\"]\n",
    "                .str.lower()\n",
    "                .str.strip()\n",
    "                # Remove parentheses and anything inside them\n",
    "                .str.replace(r\"\\(.*?\\)\", \"\", regex=True)\n",
    "                # Remove anything after a semicolon. This is usually a note,\n",
    "                # or deal price.\n",
    "                .str.replace(r\";.*\", \"\", regex=True)\n",
    "                # Standardize units\n",
    "                .str.replace(r\".g$\", \" grams\", regex=True)\n",
    "                .str.replace(r\"\\sg$\", \"grams\", regex=True)\n",
    "                .str.replace(r\"\\bgram$\", \"grams\", regex=True)\n",
    "                .str.replace(r\"pound$\", \"1 pounds\", regex=True)\n",
    "                .str.replace(r\"oz|onces|ouncues|ounce$|ounces\\*\", \"ounces\", regex=True)\n",
    "                .str.replace(\"kilogram\", \"kilograms\")\n",
    "                .str.replace(\"kg\", \"kilograms\")\n",
    "                # Remove \"online\" from any quantity\n",
    "                .str.replace(\"online\", \"\")\n",
    "                .str.strip()\n",
    "            ),\n",
    "            price=lambda df_: df_[\"price\"].str.replace(\"..\", \".\"),\n",
    "        )\n",
    "        .dropna()\n",
    "        # Remove rows where coffee is sold in a can, box, pouch, packet, or tin\n",
    "        .loc[\n",
    "            lambda df_: ~df_[\"quantity\"].str.contains(drop_terms_string, case=False),\n",
    "            :,\n",
    "        ]\n",
    "        # Split quantity into value and unit, and split price into value and currency\n",
    "        .assign(\n",
    "            # Extract number value from quantity\n",
    "            quantity_value=lambda df_: (\n",
    "                df_[\"quantity\"].str.extract(r\"(\\d+)\").astype(float)\n",
    "            ),\n",
    "            # Extract the unit from quantity column\n",
    "            quantity_unit=lambda df_: (\n",
    "                df_[\"quantity\"]\n",
    "                .str.replace(r\"(\\d+)\", \"\", regex=True)\n",
    "                .replace(r\"\\.\", \"\", regex=True)\n",
    "                .str.strip()\n",
    "                .mask(lambda s: s == \"g\", \"grams\")\n",
    "                .mask(lambda s: s == \"kilo\", \"kilograms\")\n",
    "                .str.strip()\n",
    "            ),\n",
    "            # Extract price value from price column\n",
    "            price_value=lambda df_: (\n",
    "                df_[\"price\"].str.extract(r\"(\\d+\\.\\d+|\\d+)\").astype(float)\n",
    "            ),\n",
    "            # Extract currency from price column\n",
    "            price_currency=lambda df_: (\n",
    "                df_[\"price\"]\n",
    "                .str.replace(\",\", \"\")\n",
    "                .str.replace(r\"(\\d+\\.\\d+|\\d+)\", \"\", regex=True)\n",
    "                .str.strip()\n",
    "            ),\n",
    "        )\n",
    "        # Drop the original price and quantity columns\n",
    "        .drop(columns=[\"price\", \"quantity\"])\n",
    "        # Remove rows where quantity_unit contains\n",
    "        .loc[lambda df_: ~df_[\"quantity_unit\"].str.contains(r\"\\(\", regex=True), :]\n",
    "    )\n",
    "    print(f\"Shape of original DataFrame: {df.shape}\")\n",
    "    print(f\"Shape of price_quantity: {price_quantity.shape}\")\n",
    "\n",
    "    # Merge the price_quantity DataFrame with the original DataFrame\n",
    "    return df.merge(price_quantity, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "df = df_in.pipe(tweak_df).pipe(price_quantity_split)\n",
    "\n",
    "df.quantity_unit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lbs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a new column with the quantity in pounds\"\"\"\n",
    "    to_lbs_conversion: dict[str, float] = {\n",
    "        \"ounces\": 1 / 16,\n",
    "        \"pounds\": 1,\n",
    "        \"kilograms\": 2.20462,\n",
    "        \"grams\": 0.00220462,\n",
    "    }\n",
    "\n",
    "    df[\"quantity_in_lbs\"] = np.round(\n",
    "        df[\"quantity_value\"] * df[\"quantity_unit\"].map(to_lbs_conversion), 2\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df = df_in.pipe(tweak_df).pipe(price_quantity_split).pipe(convert_to_lbs)\n",
    "\n",
    "df.groupby(\"quantity_unit\")[\n",
    "    [\"est_price\", \"quantity_value\", \"quantity_unit\", \"quantity_in_lbs\"]\n",
    "].sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Prices and Currencies\n",
    "Here we normalize the currency column to contain a standard set of ISO 4217 currency codes. This will help us with fetching exchange rates from an API later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_currency(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Standardize currencies to ISO 4217 codes.\"\"\"\n",
    "    price_currency = (\n",
    "        df.price_currency.str.upper()\n",
    "        .str.replace(r\"^\\$$\", \"USD\", regex=True)\n",
    "        .str.replace(\"PRICE: $\", \"USD\")\n",
    "        .str.replace(\"$\", \"\")\n",
    "        .str.replace(\"#\", \"GBP\")\n",
    "        .str.replace(\"¥\", \"JPY\")\n",
    "        .str.replace(\"£\", \"GBP\")\n",
    "        .str.replace(\"€\", \"EUR\")\n",
    "        .str.replace(\"POUND\", \"GBP\")\n",
    "        .str.replace(\"PESOS\", \"MXN\")\n",
    "        .str.replace(\"RMB\", \"CNY\")\n",
    "        .str.replace(\"EUROS\", \"EUR\")\n",
    "        .str.replace(\"RM\", \"MYR\")\n",
    "        .str.strip()\n",
    "        .mask(lambda s: s == \"US\", \"USD\")\n",
    "        .mask(lambda s: s == \" \", \"USD\")\n",
    "        .mask(lambda s: s == \"E\", \"EUR\")\n",
    "        .mask(lambda s: s == \"NTD\", \"TWD\")\n",
    "        .mask(lambda s: s == \"NT\", \"TWD\")\n",
    "        .mask(lambda s: s == \"\", \"USD\")\n",
    "        .mask(lambda s: s == \"HK\", \"HKD\")\n",
    "        .str.strip()\n",
    "    )\n",
    "    return df.assign(price_currency=price_currency)\n",
    "\n",
    "\n",
    "df = df_in.pipe(tweak_df).pipe(price_quantity_split).pipe(clean_currency)\n",
    "\n",
    "\n",
    "# Check that currencies make sense from original est_price column\n",
    "df.loc[:, [\"est_price\", \"price_currency\", \"price_value\"]].groupby(\n",
    "    \"price_currency\"\n",
    ").sample(3, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price_currency.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting prices to 2024 USD\n",
    "Using historical exchange rates we will convert all prices to USD. We then adjust prices from historical USD to 2024 USD using the BLS consumer price index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR / \"external/openex_exchange_rates.json\") as f:\n",
    "    currency_codes: dict[str, dict[str, float]] = dict(json.load(f))\n",
    "\n",
    "\n",
    "def convert_row(row: pd.Series) -> float | np.float_:\n",
    "    try:\n",
    "        date: str = str(row.review_date.strftime(\"%Y-%m-%d\"))\n",
    "        currency: str = str(row.price_currency)\n",
    "        value: float | np.float_ = np.round(\n",
    "            row.price_value / currency_codes[date][currency], 2\n",
    "        )\n",
    "    except KeyError:\n",
    "        value = np.nan\n",
    "    return value\n",
    "\n",
    "\n",
    "def convert_currency(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"price_usd\"] = df.apply(convert_row, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = (\n",
    "    df_in.pipe(tweak_df)\n",
    "    .pipe(price_quantity_split)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_currency)\n",
    ")\n",
    "\n",
    "\n",
    "df.groupby(\"price_currency\")[\n",
    "    [\n",
    "        \"price_usd\",\n",
    "        \"price_value\",\n",
    "        \"price_currency\",\n",
    "    ]\n",
    "].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cpi_dataframe(file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Loads and transforms the CPI data.\"\"\"\n",
    "    try:\n",
    "        cpi: pd.DataFrame = pd.read_csv(file_path)\n",
    "    except FileNotFoundError as exc:\n",
    "        raise FileNotFoundError(\n",
    "            \"CPI file is not found in the specified directory.\"\n",
    "        ) from exc\n",
    "\n",
    "    cpi.columns = cpi.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "    return (\n",
    "        cpi.drop(columns=[\"half1\", \"half2\"])\n",
    "        .melt(id_vars=\"year\", var_name=\"month\", value_name=\"cpi\")\n",
    "        .assign(\n",
    "            month=lambda df_: df_[\"month\"].apply(\n",
    "                lambda x: datetime.strptime(x, \"%b\").month\n",
    "            ),\n",
    "            date=lambda df_: pd.to_datetime(df_[[\"year\", \"month\"]].assign(day=1)),\n",
    "        )\n",
    "        .drop(columns=[\"year\", \"month\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def adjust_row(row: pd.Series, cpi_baseline: float) -> float:\n",
    "    # CPI is NaN for the current month, return the original price_usd\n",
    "    if pd.isnull(row[\"cpi\"]):\n",
    "        return row[\"price_usd\"]\n",
    "    else:\n",
    "        return np.round(row[\"price_usd\"] * (cpi_baseline / row[\"cpi\"]), 2)\n",
    "\n",
    "\n",
    "def create_cpi_adjusted_price(\n",
    "    df: pd.DataFrame, file_path: Path, date: str = \"2024-06-01\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adjusts historical price data to 2024 prices using CPI data.\n",
    "    \"\"\"\n",
    "    cpi: pd.DataFrame = load_cpi_dataframe(file_path)\n",
    "    cpi_baseline: float = cpi.loc[cpi[\"date\"] == date, \"cpi\"].values[0]\n",
    "\n",
    "    return df.merge(cpi, how=\"left\", left_on=\"review_date\", right_on=\"date\").assign(\n",
    "        price_usd_adj=lambda df_: df_.apply(\n",
    "            adjust_row, cpi_baseline=cpi_baseline, axis=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "cpi_path: Path = DATA_DIR / \"external\" / \"consumer_price_index.csv\"\n",
    "\n",
    "df = (\n",
    "    df_in.pipe(tweak_df)\n",
    "    .pipe(price_quantity_split)\n",
    "    .pipe(convert_to_lbs)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_currency)\n",
    "    .pipe(create_cpi_adjusted_price, file_path=cpi_path)\n",
    ")\n",
    "\n",
    "df.groupby(\"price_currency\")[\n",
    "    [\n",
    "        \"price_value\",\n",
    "        \"price_currency\",\n",
    "        \"price_usd\",\n",
    "        \"review_date\",\n",
    "        \"price_usd_adj\",\n",
    "    ]\n",
    "].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the price difference between the adjusted and historical prices over time\n",
    "\n",
    "(\n",
    "    df.assign(\n",
    "        price_diff=lambda df_: (df_[\"price_usd_adj\"] - df_[\"price_usd\"])\n",
    "        / df_[\"price_usd_adj\"]\n",
    "        * 100\n",
    "    ).sort_values(\"review_date\")\n",
    ").plot(\n",
    "    x=\"review_date\",\n",
    "    y=\"price_diff\",\n",
    "    title=\"% Price difference between adjusted and historical prices\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a column for price/lb using adjusted price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for price per pound\n",
    "def price_per_lbs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"price_usd_adj_per_lb\"] = np.round(\n",
    "        df[\"price_usd_adj\"] / df[\"quantity_in_lbs\"], 2\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df = (\n",
    "    df_in.pipe(tweak_df)\n",
    "    .pipe(price_quantity_split)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_currency)  # Convert to USD with historical exchange rates\n",
    "    .pipe(create_cpi_adjusted_price, file_path=cpi_path)  # Adjust for inflation\n",
    "    .pipe(convert_to_lbs)  # Convert quantities to pounds\n",
    "    .pipe(price_per_lbs)  # Calculate adjusted USD price per pound\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Coffee Origin Cleaning <a id='coffee_origin_cleaning'></a>\n",
    "[Back to top](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_countries(countries: set) -> set:\n",
    "    remove: list = [\n",
    "        \"american samoa\",\n",
    "        \"united states minor outlying islands\",\n",
    "        \"south sudan\",\n",
    "        \"south georgia and the south sandwich islands\",\n",
    "        \"british indian ocean territory\",\n",
    "        \"congo, the democratic republic of the\",\n",
    "        \"taiwan, province of china\",\n",
    "        \"guinea\",\n",
    "    ]\n",
    "\n",
    "    for r in remove:\n",
    "        try:\n",
    "            countries.remove(r)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    for c in list(countries):\n",
    "        c_new: str = c.split(\",\")[0]\n",
    "        countries.remove(c)\n",
    "        countries.add(c_new)\n",
    "\n",
    "    countries.add(\"tawain\")\n",
    "    return countries\n",
    "\n",
    "\n",
    "countries: set = tweak_countries(\n",
    "    set(unidecode(c.name.lower()) for c in pycountry.countries)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_countries(element: str, countries: set) -> str:\n",
    "    countries_found: set = set()\n",
    "    if pd.isna(element) or element == \"\":\n",
    "        return \"\"\n",
    "    for c in countries:\n",
    "        if c in element:\n",
    "            countries_found.add(c)\n",
    "    if len(countries_found) == 0:\n",
    "        return element\n",
    "    # alphabetically sort the countries found\n",
    "    countries_found = sorted(countries_found)\n",
    "    return \";\".join(countries_found)\n",
    "\n",
    "\n",
    "def clean_origin(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.assign(coffee_origin=df.coffee_origin.str.lower())\n",
    "    df[\"origin_country\"] = df.coffee_origin.apply(\n",
    "        retrieve_countries, countries=countries\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df = (\n",
    "    df_in.pipe(tweak_df)\n",
    "    .pipe(price_quantity_split)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_currency)\n",
    "    .pipe(create_cpi_adjusted_price, file_path=cpi_path)\n",
    "    .pipe(convert_to_lbs)\n",
    "    .pipe(price_per_lbs)\n",
    "    .pipe(clean_origin)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.origin_country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Export processed data <a id='export_data'></a>\n",
    "[Back to top](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_OUT: str = FILE_IN.replace(\".csv\", \"_intermediate.csv\")\n",
    "df.to_csv(DATA_DIR / \"intermediate\" / FILE_OUT, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. External Processing <a id='external_processing'></a>\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "The data exported in the previous step will be further cleaned using [OpenRefine](https://openrefine.org/). This will include cleaning up roaster names, and cleaning up and reconciling roaster and coffee origin locations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
