{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "from unidecode import unidecode\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "mpl.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7890 entries, 0 to 7889\n",
      "Data columns (total 21 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   rating                             7890 non-null   object \n",
      " 1   roaster                            7890 non-null   object \n",
      " 2   title                              7890 non-null   object \n",
      " 3   blind_assessment                   7889 non-null   object \n",
      " 4   notes                              7888 non-null   object \n",
      " 5   bottom_line                        3812 non-null   object \n",
      " 6   roaster location                   7887 non-null   object \n",
      " 7   coffee origin                      7386 non-null   object \n",
      " 8   roast level                        7488 non-null   object \n",
      " 9   agtron                             7890 non-null   object \n",
      " 10  est. price                         5852 non-null   object \n",
      " 11  review date                        7890 non-null   object \n",
      " 12  aroma                              7830 non-null   object \n",
      " 13  acidity                            3730 non-null   object \n",
      " 14  body                               7879 non-null   object \n",
      " 15  flavor                             7874 non-null   object \n",
      " 16  aftertaste                         7019 non-null   float64\n",
      " 17  url                                7890 non-null   object \n",
      " 18  acidity/structure                  2903 non-null   float64\n",
      " 19  with milk                          1118 non-null   object \n",
      " 20  refresh(enable javascript first.)  4 non-null      object \n",
      "dtypes: float64(2), object(19)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Set up directories\n",
    "BASE_DIR: Path = Path().resolve().parent\n",
    "DATA_DIR: Path = BASE_DIR / \"data\"\n",
    "RAW_DATA_DIR: Path = DATA_DIR / \"raw\"\n",
    "\n",
    "\n",
    "# Load data\n",
    "file_path_in: Path = RAW_DATA_DIR / \"25072024_reviews.csv\"\n",
    "if not file_path_in.exists():\n",
    "    raise FileNotFoundError(f\"File {file_path_in} not found.\")\n",
    "\n",
    "df_in: pd.DataFrame = pd.read_csv(file_path_in)\n",
    "df_in.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7890 entries, 0 to 7889\n",
      "Data columns (total 21 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   rating                            7890 non-null   object \n",
      " 1   roaster                           7890 non-null   object \n",
      " 2   title                             7890 non-null   object \n",
      " 3   blind_assessment                  7889 non-null   object \n",
      " 4   notes                             7888 non-null   object \n",
      " 5   bottom_line                       3812 non-null   object \n",
      " 6   roaster_location                  7887 non-null   object \n",
      " 7   coffee_origin                     7386 non-null   object \n",
      " 8   roast_level                       7488 non-null   object \n",
      " 9   agtron                            7890 non-null   object \n",
      " 10  est_price                         5852 non-null   object \n",
      " 11  review_date                       7890 non-null   object \n",
      " 12  aroma                             7830 non-null   object \n",
      " 13  acidity                           3730 non-null   object \n",
      " 14  body                              7879 non-null   object \n",
      " 15  flavor                            7874 non-null   object \n",
      " 16  aftertaste                        7019 non-null   float64\n",
      " 17  url                               7890 non-null   object \n",
      " 18  acidity/structure                 2903 non-null   float64\n",
      " 19  with_milk                         1118 non-null   object \n",
      " 20  refresh(enable_javascript_first)  4 non-null      object \n",
      "dtypes: float64(2), object(19)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Cleanup column names\n",
    "df_in.columns = (\n",
    "    df_in.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\".\", \"\")\n",
    ")\n",
    "\n",
    "df_in.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7890 entries, 0 to 7889\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   rating            7886 non-null   float64       \n",
      " 1   roaster           7890 non-null   object        \n",
      " 2   title             7890 non-null   object        \n",
      " 3   blind_assessment  7889 non-null   object        \n",
      " 4   notes             7888 non-null   object        \n",
      " 5   bottom_line       3812 non-null   object        \n",
      " 6   roaster_location  7887 non-null   object        \n",
      " 7   coffee_origin     7386 non-null   object        \n",
      " 8   roast_level       7488 non-null   object        \n",
      " 9   est_price         5849 non-null   object        \n",
      " 10  review_date       7890 non-null   datetime64[ns]\n",
      " 11  aroma             7829 non-null   float64       \n",
      " 12  acidity           6611 non-null   float64       \n",
      " 13  body              7878 non-null   float64       \n",
      " 14  flavor            7873 non-null   float64       \n",
      " 15  aftertaste        7019 non-null   float64       \n",
      " 16  url               7890 non-null   object        \n",
      " 17  with_milk         1118 non-null   object        \n",
      " 18  agtron_external   7576 non-null   float64       \n",
      " 19  agtron_ground     7581 non-null   float64       \n",
      " 20  is_espresso       7890 non-null   bool          \n",
      "dtypes: bool(1), datetime64[ns](1), float64(8), object(11)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "def tweak_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Initial data cleaning pipeline.\n",
    "    - Converts non-standard missing values to NaN.\n",
    "    - Strips whitespace from string columns.\n",
    "    - Parses and standardizes date and numeric fields.\n",
    "    - Splits the \"agtron\" column into \"agtron_external\" and \"agtron_ground\".\n",
    "    - Derives new flags (e.g., is_espresso).\n",
    "    - Drops unnecessary or redundant columns.\n",
    "    \"\"\"\n",
    "    strings_to_nan = [\"\", \"NR\", \"N/A\", \"na\", \"NA\", \"Not Available\"]\n",
    "    return (\n",
    "        df.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "        .assign(\n",
    "            review_date=lambda df_: pd.to_datetime(df_[\"review_date\"], format=\"%B %Y\"),\n",
    "            # Combine acidity and acidity/structure into one column\n",
    "            acidity=lambda df_: pd.to_numeric(\n",
    "                df_[\"acidity\"].fillna(df_[\"acidity/structure\"]), errors=\"coerce\"\n",
    "            ),\n",
    "            # Split the agtron column into external and ground\n",
    "            agtron_external=lambda df_: pd.to_numeric(\n",
    "                df_[\"agtron\"].str.split(\"/\", expand=True)[0].str.strip(),\n",
    "                errors=\"coerce\",\n",
    "            ).where(lambda x: x <= 100),\n",
    "            agtron_ground=lambda df_: pd.to_numeric(\n",
    "                df_[\"agtron\"].str.split(\"/\", expand=True)[1].str.strip(),\n",
    "                errors=\"coerce\",\n",
    "            ).where(lambda x: x <= 100),\n",
    "            # Flag espresso roasts\n",
    "            is_espresso=lambda df_: (\n",
    "                df_[\"title\"].str.contains(\"espresso\", case=False, na=False)\n",
    "                | df_[\"with_milk\"].notnull()\n",
    "            ),\n",
    "        )\n",
    "        .replace(strings_to_nan, np.nan)\n",
    "        .drop(\n",
    "            columns=[\"acidity/structure\", \"agtron\", \"refresh(enable_javascript_first)\"]\n",
    "        )\n",
    "        .astype(\n",
    "            {\n",
    "                k: \"float\"\n",
    "                for k in [\n",
    "                    \"acidity\",\n",
    "                    \"rating\",\n",
    "                    \"aroma\",\n",
    "                    \"body\",\n",
    "                    \"flavor\",\n",
    "                    \"aftertaste\",\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "df: pd.DataFrame = tweak_df(df_in)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price and Quantity Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list of quantity terms to drop from the dataset\n",
    "drop_terms: list[str] = [\n",
    "    r\"\\bcan(?:s)?\\b\",\n",
    "    r\"\\bbox(?:es|ed)?\\b\",\n",
    "    r\"\\bcapsule(?:s)?\\b\",\n",
    "    r\"\\bK-\\b\",\n",
    "    r\"\\bflask(?:s)?\\b\",\n",
    "    r\"\\bcup(?:s)?\\b\",\n",
    "    r\"\\bbag(?:s)?\\b\",\n",
    "    r\"\\bconcentrate(?:s)?\\b\",\n",
    "    r\"\\bdisc(?:s)?\\b\",\n",
    "    r\"\\bbottle(?:s)?\\b\",\n",
    "    r\"\\bpod(?:s)?\\b\",\n",
    "    r\"\\bpouch(?:es)?\\b\",\n",
    "    r\"\\bpacket(?:s)?\\b\",\n",
    "    r\"\\btin(?:s)?\\b\",\n",
    "    r\"\\binstant\\b\",\n",
    "    r\"\\bsachet(?:s)?\\b\",\n",
    "    r\"\\bvue\\b\",\n",
    "    r\"\\bsingle-serve(?:s)?\\b\",\n",
    "    r\"\\bfluid(?:s)?\\b\",\n",
    "]\n",
    "# Regex drop term string\n",
    "drop_terms_string: str = r\"|\".join(drop_terms)\n",
    "\n",
    "# Regex patterns\n",
    "remove_parentheses_pattern: re.Pattern[str] = re.compile(r\"\\(.*?\\)\")\n",
    "remove_notes_pattern: re.Pattern[str] = re.compile(r\";.*\")\n",
    "remove_online_pattern: re.Pattern[str] = re.compile(r\"online\")\n",
    "standardize_units_patterns: list[tuple[re.Pattern[str], str]] = [\n",
    "    (re.compile(r\"\\bgrams\"), \"grams\"),\n",
    "    (re.compile(r\"\\bgram\\b\"), \"grams\"),\n",
    "    (re.compile(r\".g$\"), \" grams\"),\n",
    "    (re.compile(r\"pound$\"), \"1 pounds\"),\n",
    "    (re.compile(r\"oz|onces|ouncues|ounce$|ounces\\*\"), \"ounces\"),\n",
    "    (re.compile(r\"kilogram\"), \"kilograms\"),\n",
    "    (re.compile(r\"kg\"), \"kilograms\"),\n",
    "    (re.compile(r\"capsulte\"), \"capsule\"),\n",
    "]\n",
    "number_pattern: re.Pattern[str] = re.compile(r\"(\\d+(?:\\.\\d+)?)\")\n",
    "currency_pattern: re.Pattern[str] = re.compile(r\"(\\d+\\.\\d+|\\d+)\")\n",
    "\n",
    "# Final quantity units\n",
    "allowed_quantity_units: list[str] = [\"ounces\", \"pounds\", \"grams\", \"kilograms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_quantity_column(column: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        column.str.lower()\n",
    "        .str.strip()\n",
    "        # Remove parentheses and notes\n",
    "        .str.replace(remove_parentheses_pattern, \"\", regex=True)\n",
    "        .str.replace(remove_notes_pattern, \"\", regex=True)\n",
    "        # Clean and standardize quantity units\n",
    "        .pipe(\n",
    "            lambda s: s.replace(\n",
    "                {pat: repl for pat, repl in standardize_units_patterns},\n",
    "                regex=True,\n",
    "            )\n",
    "        )\n",
    "        # Remove \"online\" from any quantity\n",
    "        .str.replace(remove_online_pattern, \"\", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "\n",
    "def prep_price_column(column: pd.Series) -> pd.Series:\n",
    "    return column\n",
    "\n",
    "\n",
    "def extract_quantity_value(column: pd.Series) -> pd.Series:\n",
    "    return column.str.extract(number_pattern).astype(float)\n",
    "\n",
    "\n",
    "def extract_quantity_unit(column: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        column.str.replace(number_pattern, \"\", regex=True)\n",
    "        .replace(r\"\\.\", \"\", regex=True)\n",
    "        .str.strip()\n",
    "        .mask(lambda s: s == \"g\", \"grams\")\n",
    "        .mask(lambda s: s == \"kilo\", \"kilograms\")\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_price_value(column: pd.Series) -> pd.Series:\n",
    "    return column.str.extract(currency_pattern).astype(float)\n",
    "\n",
    "\n",
    "def extract_price_currency(column: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        column.str.replace(\",\", \"\")\n",
    "        .str.replace(currency_pattern, \"\", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "\n",
    "def create_price_quantity_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Split the est_price column into price and quantity columns\n",
    "    return (\n",
    "        df.assign(\n",
    "            # Split est_price into price and quantity, removing commas\n",
    "            **df[\"est_price\"]\n",
    "            .str.split(\"/\", n=1, expand=True)\n",
    "            .replace(\",\", \"\", regex=True)\n",
    "            .rename(columns={0: \"price\", 1: \"quantity\"})\n",
    "        )\n",
    "        # Filter out rows with unwanted terms in the quantity column\n",
    "        .loc[\n",
    "            lambda x: ~x[\"quantity\"].str.contains(\n",
    "                drop_terms_string, case=False, na=False\n",
    "            ),\n",
    "            :,\n",
    "        ]\n",
    "        .assign(\n",
    "            quantity=lambda x: prep_quantity_column(x[\"quantity\"]),\n",
    "            price=lambda x: prep_price_column(x[\"price\"]),\n",
    "        )\n",
    "        .assign(\n",
    "            quantity_unit=lambda x: extract_quantity_unit(x[\"quantity\"]),\n",
    "            quantity_value=lambda x: extract_quantity_value(x[\"quantity\"]),\n",
    "            price_value=lambda x: extract_price_value(x[\"price\"]),\n",
    "            price_currency=lambda x: extract_price_currency(x[\"price\"]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "df = df_in.pipe(tweak_df).pipe(create_price_quantity_columns)\n",
    "df[\n",
    "    [\n",
    "        \"est_price\",\n",
    "        \"price\",\n",
    "        \"quantity\",\n",
    "        \"quantity_value\",\n",
    "        \"quantity_unit\",\n",
    "        \"price_value\",\n",
    "        \"price_currency\",\n",
    "    ]\n",
    "].dropna().sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lbs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return dataframe with a new column convertign quantity into lbs\"\"\"\n",
    "    convert_to_lbs_map: dict[str, float] = {\n",
    "        \"ounces\": 1 / 16,\n",
    "        \"pounds\": 1,\n",
    "        \"kilograms\": 2.20462,\n",
    "        \"grams\": 0.00220462,\n",
    "    }\n",
    "\n",
    "    df[\"quantity_in_lbs\"] = np.round(\n",
    "        df[\"quantity_value\"] * df[\"quantity_unit\"].map(convert_to_lbs_map), 3\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df = df_in.pipe(tweak_df).pipe(create_price_quantity_columns).pipe(convert_to_lbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Prices and Currencies\n",
    "Here we normalize the currency column to contain a standard set of ISO 4217 currency codes. This will help us with fetching exchange rates from an API later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_currency(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Standardize currencies to ISO 4217 codes.\"\"\"\n",
    "    currency_map = {\n",
    "        \"PRICE: $\": \"USD\",\n",
    "        \"#\": \"GBP\",\n",
    "        \"¥\": \"JPY\",\n",
    "        \"£\": \"GBP\",\n",
    "        \"€\": \"EUR\",\n",
    "        \"POUND\": \"GBP\",\n",
    "        \"PESOS\": \"COP\",  # Only pesos are from colombian roasts so COP\n",
    "        \"RMB\": \"CNY\",\n",
    "        \"EUROS\": \"EUR\",\n",
    "        \"RM\": \"MYR\",\n",
    "    }\n",
    "    price_currency = (\n",
    "        df.price_currency.str.upper()\n",
    "        .str.replace(r\"^\\$$\", \"USD\", regex=True)\n",
    "        .replace(currency_map, regex=False)\n",
    "        .replace(r\"\\$\", \"\", regex=True)\n",
    "        .str.strip()\n",
    "        .mask(lambda s: s == \"US\", \"USD\")\n",
    "        .mask(lambda s: s == \" \", \"USD\")\n",
    "        .mask(lambda s: s == \"E\", \"EUR\")\n",
    "        .mask(lambda s: s == \"NTD\", \"TWD\")\n",
    "        .mask(lambda s: s == \"NT\", \"TWD\")\n",
    "        .mask(lambda s: s == \"\", \"USD\")\n",
    "        .mask(lambda s: s == \"HK\", \"HKD\")\n",
    "        .str.strip()\n",
    "    )\n",
    "    return df.assign(price_currency=price_currency)\n",
    "\n",
    "\n",
    "df = (\n",
    "    df_in.pipe(tweak_df)\n",
    "    .pipe(create_price_quantity_columns)\n",
    "    .pipe(convert_to_lbs)\n",
    "    .pipe(clean_currency)\n",
    ")\n",
    "\n",
    "# Check that currencies make sense from original est_price column\n",
    "df.loc[\n",
    "    :, [\"est_price\", \"price_currency\", \"price_value\", \"title\", \"coffee_origin\"]\n",
    "].groupby(\n",
    "    \"price_currency\",\n",
    ").sample(3, replace=True)\n",
    "\n",
    "\n",
    "price_currency_counts = df.price_currency.value_counts()\n",
    "\n",
    "price_currency_counts[price_currency_counts > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price_currency.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflation adjustment and converting to USD\n",
    "Using historical exchange rates we will convert all prices to USD. We then adjust prices from historical USD to 2024 USD using the BLS [consumer price index](https://data.bls.gov/PDQWeb/cu).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR / \"external/openex_exchange_rates.json\") as f:\n",
    "    currency_codes: dict[str, dict[str, float]] = dict(json.load(f))\n",
    "\n",
    "\n",
    "def row_convert_currency(row: pd.Series) -> float | np.float64:\n",
    "    \"\"\"Converts currency for a row of a Series. Returning np.nan on error\"\"\"\n",
    "    try:\n",
    "        date: str = str(row.review_date.strftime(\"%Y-%m-%d\"))\n",
    "        currency: str = str(row.price_currency)\n",
    "        value: float | np.float64 = np.round(\n",
    "            row.price_value / currency_codes[date][currency], 2\n",
    "        )\n",
    "    except KeyError:\n",
    "        value = np.nan\n",
    "    return value\n",
    "\n",
    "\n",
    "def convert_currency(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"price_usd\"] = df.apply(row_convert_currency, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = (\n",
    "    df_in.pipe(tweak_df)\n",
    "    .pipe(create_price_quantity_columns)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_currency)\n",
    ")\n",
    "\n",
    "\n",
    "df.groupby(\"price_currency\")[\n",
    "    [\n",
    "        \"price_usd\",\n",
    "        \"price_value\",\n",
    "        \"price_currency\",\n",
    "    ]\n",
    "].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cpi_dataframe(file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Loads and transforms Consumer Price Index data.\"\"\"\n",
    "    try:\n",
    "        cpi: pd.DataFrame = pd.read_csv(file_path)\n",
    "    except FileNotFoundError as exc:\n",
    "        raise FileNotFoundError(\n",
    "            \"CPI file is not found in the specified directory.\"\n",
    "        ) from exc\n",
    "\n",
    "    # Cleanup CPI data column names. Columns will be year, the months, and \"half\"\n",
    "    cpi.columns = cpi.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "    return (\n",
    "        cpi.drop(columns=[\"half1\", \"half2\"])\n",
    "        .melt(id_vars=\"year\", var_name=\"month\", value_name=\"cpi\")\n",
    "        .assign(\n",
    "            month=lambda df_: df_[\"month\"].apply(\n",
    "                lambda x: datetime.strptime(x, \"%b\").month\n",
    "            ),\n",
    "            date=lambda df_: pd.to_datetime(df_[[\"year\", \"month\"]].assign(day=1)),\n",
    "        )\n",
    "        .drop(columns=[\"year\", \"month\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def adjust_row(row: pd.Series, cpi_baseline: float) -> float:\n",
    "    # CPI is NaN for the current month, return the original price_usd\n",
    "    if pd.isnull(row[\"cpi\"]):\n",
    "        return row[\"price_usd\"]\n",
    "    else:\n",
    "        return np.round(row[\"price_usd\"] * (cpi_baseline / row[\"cpi\"]), 2)\n",
    "\n",
    "\n",
    "def create_cpi_adjusted_price(\n",
    "    df: pd.DataFrame, file_path: Path, date: str = \"2024-06-01\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adjusts historical price data to 2024 prices using CPI data.\n",
    "    \"\"\"\n",
    "    cpi: pd.DataFrame = load_cpi_dataframe(file_path)\n",
    "    cpi_baseline: float = cpi.loc[cpi[\"date\"] == date, \"cpi\"].values[0]\n",
    "\n",
    "    return df.merge(cpi, how=\"left\", left_on=\"review_date\", right_on=\"date\").assign(\n",
    "        price_usd_adj=lambda df_: df_.apply(\n",
    "            adjust_row, cpi_baseline=cpi_baseline, axis=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "cpi_path: Path = DATA_DIR / \"external\" / \"consumer_price_index.csv\"\n",
    "\n",
    "df = (\n",
    "    df_in.pipe(tweak_df)\n",
    "    .pipe(create_price_quantity_columns)\n",
    "    .pipe(convert_to_lbs)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_currency)\n",
    "    .pipe(create_cpi_adjusted_price, file_path=cpi_path)\n",
    ")\n",
    "\n",
    "df.groupby(\"price_currency\")[\n",
    "    [\n",
    "        \"price_value\",\n",
    "        \"price_currency\",\n",
    "        \"price_usd\",\n",
    "        \"review_date\",\n",
    "        \"price_usd_adj\",\n",
    "    ]\n",
    "].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the price difference between the adjusted and historical prices over time\n",
    "\n",
    "(\n",
    "    df.assign(\n",
    "        price_diff=lambda df_: (df_[\"price_usd_adj\"] - df_[\"price_usd\"])\n",
    "        / df_[\"price_usd_adj\"]\n",
    "        * 100\n",
    "    ).sort_values(\"review_date\")\n",
    ").plot(\n",
    "    x=\"review_date\",\n",
    "    y=\"price_diff\",\n",
    "    title=\"% Price difference between adjusted and historical prices\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a column for $USD/lb using adjusted price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for price per pound\n",
    "def price_per_lbs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"price_usd_adj_per_lb\"] = np.round(\n",
    "        df[\"price_usd_adj\"] / df[\"quantity_in_lbs\"], 2\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df = (\n",
    "    df_in.pipe(tweak_df)\n",
    "    .pipe(create_price_quantity_columns)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_currency)  # Convert to USD with historical exchange rates\n",
    "    .pipe(create_cpi_adjusted_price, file_path=cpi_path)  # Adjust for inflation\n",
    "    .pipe(convert_to_lbs)  # Convert quantities to pounds\n",
    "    .pipe(price_per_lbs)  # Calculate adjusted USD price per pound\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coffee Origin Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_countries(\n",
    "    add: list[str] | None = None, remove: list[str] | None = None\n",
    ") -> set:\n",
    "    \"\"\"Return a modified list of country names from pycountry\"\"\"\n",
    "\n",
    "    countries = set(unidecode(c.name.lower()) for c in pycountry.countries)\n",
    "\n",
    "    if remove:\n",
    "        for r in remove:\n",
    "            try:\n",
    "                countries.remove(r)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    for c in list(countries):\n",
    "        if \"(\" in c:\n",
    "            countries.remove(c)\n",
    "            continue\n",
    "        c_new: str = c.split(\",\")[0]\n",
    "        countries.remove(c)\n",
    "        countries.add(c_new)\n",
    "\n",
    "    if add:\n",
    "        for a in add:\n",
    "            countries.add(a)\n",
    "    return countries\n",
    "\n",
    "\n",
    "standardized_countries: set[str] = get_standard_countries()\n",
    "\n",
    "print(pd.Series(list(standardized_countries)).sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "\n",
    "display(df.coffee_origin.sample(100))\n",
    "\n",
    "# \";\" means multiple\n",
    "# \"and\" means multiple\n",
    "# \"undisclosed\" means multiple\n",
    "# \"various\" means multiple\n",
    "# lowercase, strip whitespace\n",
    "# remove punctuation, apostrophes\n",
    "# hawaii, sanna, gedeo, kilimanjaro cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_countries(element: str, countries: set) -> str:\n",
    "    countries_found: set = set()\n",
    "    if pd.isna(element) or element == \"\":\n",
    "        return \"\"\n",
    "    for c in countries:\n",
    "        if c in element:\n",
    "            countries_found.add(c)\n",
    "    if len(countries_found) == 0:\n",
    "        return element\n",
    "    # alphabetically sort the countries found\n",
    "    countries_found = sorted(countries_found)\n",
    "    return \";\".join(countries_found)\n",
    "\n",
    "\n",
    "def clean_origin(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.assign(coffee_origin=df.coffee_origin.str.lower())\n",
    "    df[\"origin_country\"] = df.coffee_origin.apply(\n",
    "        retrieve_countries, countries=standardized_countries\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df = (\n",
    "    df_in.pipe(tweak_df)\n",
    "    .pipe(create_price_quantity_columns)\n",
    "    .pipe(clean_currency)\n",
    "    .pipe(convert_currency)\n",
    "    .pipe(create_cpi_adjusted_price, file_path=cpi_path)\n",
    "    .pipe(convert_to_lbs)\n",
    "    .pipe(price_per_lbs)\n",
    "    .pipe(clean_origin)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.origin_country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out: Path = Path(f\"{file_path_in.stem}_intermediate{file_path_in.suffix}\")\n",
    "file_path_out = DATA_DIR / \"intermediate\" / file_out\n",
    "if not file_path_out.exists():\n",
    "    raise FileNotFoundError(f\"File {file_path_out} not found.\")\n",
    "\n",
    "df.to_csv(DATA_DIR / \"intermediate\" / file_path_out, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
